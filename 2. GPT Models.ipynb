{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda3fbd5",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\" width=150px> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>Generative AI with OpenAI API</h1>\n",
    "<h1>GPT Models</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a05e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "import termcolor\n",
    "from termcolor import colored\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "import tqdm as tq\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135de5a",
   "metadata": {},
   "source": [
    "We start by printing out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b252db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.7\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.3.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 3a7a9a8b6856eb5855cd2ac76a384e203382ab54\n",
      "\n",
      "numpy     : 1.26.4\n",
      "matplotlib: 3.8.0\n",
      "pandas    : 2.2.3\n",
      "openai    : 1.30.5\n",
      "tqdm      : 4.66.4\n",
      "json      : 2.0.9\n",
      "termcolor : 2.4.0\n",
      "watermark : 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dde41d",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343112a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('d4sci.mplstyle')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f7d30",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ee6b1",
   "metadata": {},
   "source": [
    "The first step is generate API key on the OpenAI website and store it as the \"OPENAI_API_KEY\" variable in your local environment. Without it we won't be able to do anything. You can find your API key in your using settings: https://help.openai.com/en/articles/4936850-where-do-i-find-my-secret-api-key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a6112",
   "metadata": {},
   "source": [
    "Then we are ready to instantiate the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188a3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130bb5d8",
   "metadata": {},
   "source": [
    "We start by getting a list of supported models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b592b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = json.loads(client.models.list().model_dump_json())[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612fb10",
   "metadata": {},
   "source": [
    "In total we have 49 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c41b5cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af6dba",
   "metadata": {},
   "source": [
    "Along with some information about each model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0bb7b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'dall-e-3',\n",
       "  'created': 1698785189,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'},\n",
       " {'id': 'dall-e-2',\n",
       "  'created': 1698798177,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'},\n",
       " {'id': 'o1-mini-2024-09-12',\n",
       "  'created': 1725648979,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'},\n",
       " {'id': 'gpt-4o-mini-realtime-preview-2024-12-17',\n",
       "  'created': 1734112601,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'},\n",
       " {'id': 'o1-preview-2024-09-12',\n",
       "  'created': 1725648865,\n",
       "  'object': 'model',\n",
       "  'owned_by': 'system'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb860a",
   "metadata": {},
   "source": [
    "But let's just get a list of model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0722120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage-002\n",
      "chatgpt-4o-latest\n",
      "dall-e-2\n",
      "dall-e-3\n",
      "davinci-002\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-16k-0613\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0125-preview\n",
      "gpt-4-0613\n",
      "gpt-4-1106-preview\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-preview\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-2024-08-06\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini-audio-preview\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-realtime-preview\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "o1-mini\n",
      "o1-mini-2024-09-12\n",
      "o1-preview\n",
      "o1-preview-2024-09-12\n",
      "omni-moderation-2024-09-26\n",
      "omni-moderation-latest\n",
      "text-embedding-3-large\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "tts-1\n",
      "tts-1-1106\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(sorted([model[\"id\"] for model in model_list])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199013c7",
   "metadata": {},
   "source": [
    "## Basic Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e2f781",
   "metadata": {},
   "source": [
    "The recommended model for exploration is `gpt-3.5-turbo`, so we'll stick with it for now. The basic setup is relatively straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16b5ee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 ms, sys: 2.83 ms, total: 14.8 ms\n",
      "Wall time: 925 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What was Superman's weakness?\"\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3bfb20",
   "metadata": {},
   "source": [
    "Which produces a response object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99f85559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a0aeb",
   "metadata": {},
   "source": [
    "Which we can treat as a named tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac44521",
   "metadata": {},
   "source": [
    "The model answer can be found in the \"message\" dictionary inside the \"choices\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4536fb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Superman's weakness is Kryptonite, a mineral from his home planet Krypton that emits radiation harmful to Kryptonians like himself. Exposure to Kryptonite weakens Superman and can even be fatal if he is exposed to a large amount of it.\", role='assistant', function_call=None, tool_calls=None, refusal=None))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "391575e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Superman's weakness is Kryptonite, a mineral from his home planet Krypton that emits radiation harmful to Kryptonians like himself. Exposure to Kryptonite weakens Superman and can even be fatal if he is exposed to a large amount of it.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2fd86",
   "metadata": {},
   "source": [
    "To request multiple answers, we must include the `n` parameter with the number of answers we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980a1518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.11 ms, sys: 2.54 ms, total: 11.6 ms\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What are the different kinds of Kryptonite?\"\n",
    "        },\n",
    "    ],\n",
    "    n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d449f3e",
   "metadata": {},
   "source": [
    "And we can access each of the answers individually int he choices list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e6dedff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are several different types of Kryptonite in DC Comics, each with unique effects on Superman and other Kryptonians:\n",
      "\n",
      "1. Green Kryptonite: The most common form of Kryptonite, green Kryptonite is deadly to Kryptonians and weakens them upon exposure. Prolonged exposure can be fatal.\n",
      "\n",
      "2. Red Kryptonite: Red Kryptonite has unpredictable effects on Kryptonians, causing temporary changes in their personalities, powers, or physical appearance.\n",
      "\n",
      "3. Blue Kryptonite: Blue Kryptonite has similar effects to green Kryptonite but is specifically harmful to Bizarro, a flawed duplicate of Superman.\n",
      "\n",
      "4. Gold Kryptonite: Gold Kryptonite permanently removes a Kryptonian's powers, rendering them completely human.\n",
      "\n",
      "5. Black Kryptonite: Black Kryptonite can split a Kryptonian into two separate beings, one good and one evil, or merge two separate beings into one.\n",
      "\n",
      "6. White Kryptonite: White Kryptonite is toxic to plant life, causing plants to wither and die upon exposure.\n",
      "\n",
      "7. X-Kryptonite: X-Kryptonite is synthetic Kryptonite created by humans that can have various effects on Kryptonians, depending on how it is crafted.\n",
      "\n",
      "8. Pink Kryptonite: Pink Kryptonite has been used in comic storylines to give Superman temporary homosexual desires.\n",
      "==========\n",
      "\n",
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are several different kinds of Kryptonite in the DC Comics universe, each with unique properties and effects on Superman and other Kryptonians. Some of the most well-known types of Kryptonite include:\n",
      "\n",
      "1. Green Kryptonite: The most common form of Kryptonite, green Kryptonite is deadly to Kryptonians, weakening them and eventually killing them if they are exposed to it for long periods of time.\n",
      "\n",
      "2. Red Kryptonite: Red Kryptonite has unpredictable effects on Kryptonians, causing temporary physical or psychological changes in Superman whenever he is exposed to it.\n",
      "\n",
      "3. Blue Kryptonite: Blue Kryptonite has similar effects to Green Kryptonite but is specifically harmful to Bizarro, a flawed clone of Superman.\n",
      "\n",
      "4. Gold Kryptonite: Gold Kryptonite permanently removes a Kryptonian's powers, rendering them powerless and vulnerable.\n",
      "\n",
      "5. White Kryptonite: White Kryptonite is toxic to plant life, making it lethal to any plant-based organisms.\n",
      "\n",
      "6. Black Kryptonite: Black Kryptonite can split a Kryptonian into two separate beings, each representing a different aspect of their personality.\n",
      "\n",
      "7. X-Kryptonite: X-Kryptonite is a synthetic form of Kryptonite that grants superpowers to non-Kryptonians, but has unpredictable and potentially dangerous side effects.\n",
      "\n",
      "These are just a few examples of the different kinds of Kryptonite that exist in the DC Comics universe, each with its own unique properties and effects on Superman and other Kryptonians.\n",
      "==========\n",
      "\n",
      "==========\n",
      "Assistant\n",
      "==========\n",
      "There are several different kinds of Kryptonite in the DC Comics universe, each with unique properties and effects on Kryptonians such as Superman. Some of the most well-known types of Kryptonite include:\n",
      "\n",
      "1. Green Kryptonite: The most common form of Kryptonite, green Kryptonite weakens Kryptonians and can eventually kill them if they are exposed to it for an extended period of time.\n",
      "\n",
      "2. Red Kryptonite: Red Kryptonite has unpredictable effects on Kryptonians, causing temporary changes in their behavior or powers.\n",
      "\n",
      "3. Blue Kryptonite: Blue Kryptonite is harmless to Kryptonians but has detrimental effects on Bizarro, a flawed clone of Superman.\n",
      "\n",
      "4. Gold Kryptonite: Gold Kryptonite permanently removes a Kryptonian's powers, rendering them completely human.\n",
      "\n",
      "5. White Kryptonite: White Kryptonite is lethal to plant-based life forms, such as Kryptonian flora, but has no effect on Kryptonians themselves.\n",
      "\n",
      "6. Black Kryptonite: Black Kryptonite can split a Kryptonian into two separate beings, one good and one evil.\n",
      "\n",
      "These are just a few examples of the different types of Kryptonite found in the DC Comics universe.\n",
      "==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for output in response.choices:\n",
    "    print(\"==========\")\n",
    "    print(output.message.role.title()) \n",
    "    print(\"==========\")\n",
    "    print(output.message.content)\n",
    "    print(\"==========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efc9cc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=854, prompt_tokens=17, total_tokens=871, prompt_tokens_details={'cached_tokens': 0, 'audio_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57fbdf8",
   "metadata": {},
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87bd5963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.31 ms, sys: 2.53 ms, total: 10.8 ms\n",
      "Wall time: 583 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a dad joke\"},\n",
    "    ],\n",
    "    temperature=1.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0f7d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two tired. üòù\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9c35c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.18 ms, sys: 2.33 ms, total: 11.5 ms\n",
      "Wall time: 538 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a dad joke\"},\n",
    "    ],\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31df859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two tired!\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667e86da",
   "metadata": {},
   "source": [
    "# Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e125d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(messages, functions):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        # Define the functions the model is allowed to use\n",
    "        functions=functions\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53163994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "#         print(message)\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"assistant\" and message['function_call']:\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message['function_call']:\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message['role']]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message.name}): {message.content}\\n\", role_to_color[message.role]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e42175",
   "metadata": {},
   "source": [
    "Let's create some function specifications to interface with a hypothetical weather API. We'll pass these function specification to the Chat Completions API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6692b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db83082",
   "metadata": {},
   "source": [
    "If we prompt the model about the current weather, it will respond with some clarifying questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c01ef0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\n",
    "    })\n",
    "\n",
    "messages.append(\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"What's the weather like today\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a5c7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat(messages, functions=functions)\n",
    "\n",
    "assistant_message = chat_response.choices[0].message\n",
    "\n",
    "messages.append({\n",
    " \"role\":  assistant_message.role,\n",
    " \"content\":  assistant_message.content,\n",
    " \"function_call\":  assistant_message.function_call,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee6c4a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\n",
      "\u001b[0m\n",
      "\u001b[32muser: What's the weather like today\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Sure, I can help with that. Could you please provide me with your current location or the city and state you are in?\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94309538",
   "metadata": {},
   "source": [
    "Once we provide the missing information, it will generate the appropriate function arguments for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a670884",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"I'm in New York, NY.\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc3ee6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat(messages, functions=functions)\n",
    "\n",
    "assistant_message = chat_response.choices[0].message\n",
    "\n",
    "messages.append({\n",
    " \"role\":  assistant_message.role,\n",
    " \"content\":  assistant_message.content,\n",
    " \"function_call\":  assistant_message.function_call,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00614f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\n",
      "\u001b[0m\n",
      "\u001b[32muser: What's the weather like today\n",
      "\u001b[0m\n",
      "\u001b[34massistant: Sure, I can help with that. Could you please provide me with your current location or the city and state you are in?\n",
      "\u001b[0m\n",
      "\u001b[32muser: I'm in New York, NY.\n",
      "\u001b[0m\n",
      "\u001b[34massistant: FunctionCall(arguments='{\"location\":\"New York, NY\",\"format\":\"celsius\"}', name='get_current_weather')\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3753cd",
   "metadata": {},
   "source": [
    "# Prompt-Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765fa89",
   "metadata": {},
   "source": [
    "## Few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2487d",
   "metadata": {},
   "source": [
    "We can also provide several examples of mappings between input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "655c4a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This last-minute change means we can't spend excessive time on the client's project.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful, pattern-following assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Help me translate the following corporate jargon into plain English.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Sure, I'd be happy to!\"},\n",
    "        {\"role\": \"user\", \"content\": \"New synergies will help drive top-line growth.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Things working well together will increase revenue.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Let's circle back when we have more bandwidth to touch base on opportunities for increased leverage.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Let's talk later when we're less busy about how to do better.\"},\n",
    "        {\"role\": \"user\", \"content\": \"This late pivot means we don't have time to boil the ocean for the client deliverable.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462c73a",
   "metadata": {},
   "source": [
    "## Formatted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b7e04de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.19 ms, sys: 2.19 ms, total: 11.4 ms\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "userInput = \"blueberry pancakes\"\n",
    "\n",
    "prompt = \"\"\"return a recipe for %s.\n",
    "        Provide your response as a JSON object with the following schema:\n",
    "        {\"dish\": \"%s\", \"ingredients\": [\"\", \"\", ...],\n",
    "        \"instructions\": [\"\", \"\", ... ]}\"\"\" % (userInput, userInput)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "          model = \"gpt-3.5-turbo\",\n",
    "          messages = [\n",
    "            { \"role\": \"system\", \"content\": \"You are a helpful recipe assistant.\"},\n",
    "            { \"role\": \"user\",   \"content\": prompt }\n",
    "          ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f76eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d5954d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = json.loads(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "615df6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dish': 'blueberry pancakes',\n",
      " 'ingredients': ['1 cup all-purpose flour',\n",
      "                 '2 tbsp sugar',\n",
      "                 '1 tsp baking powder',\n",
      "                 '1/2 tsp baking soda',\n",
      "                 '1/4 tsp salt',\n",
      "                 '1 cup buttermilk',\n",
      "                 '1 large egg',\n",
      "                 '2 tbsp melted butter',\n",
      "                 '1 cup fresh blueberries',\n",
      "                 'Butter or oil for cooking'],\n",
      " 'instructions': ['In a large bowl, whisk together flour, sugar, baking '\n",
      "                  'powder, baking soda, and salt.',\n",
      "                  'In a separate bowl, mix buttermilk, egg, and melted butter.',\n",
      "                  'Pour the wet ingredients into the dry ingredients and stir '\n",
      "                  \"until just combined. Be careful not to overmix; it's okay \"\n",
      "                  'if the batter is a bit lumpy.',\n",
      "                  'Gently fold in the fresh blueberries.',\n",
      "                  'Heat a non-stick skillet or griddle over medium heat and '\n",
      "                  'add a small amount of butter or oil.',\n",
      "                  'Pour about 1/4 cup of batter onto the skillet for each '\n",
      "                  'pancake.',\n",
      "                  'Cook until bubbles form on the surface of the pancake, then '\n",
      "                  'flip and cook for another 1-2 minutes until golden brown.',\n",
      "                  'Repeat with the remaining batter, adding more butter or oil '\n",
      "                  'to the skillet as needed.',\n",
      "                  'Serve the blueberry pancakes warm with maple syrup, '\n",
      "                  'additional blueberries, and a pat of butter.']}\n"
     ]
    }
   ],
   "source": [
    "pprint(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6b57aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 cup all-purpose flour',\n",
       " '2 tbsp sugar',\n",
       " '1 tsp baking powder',\n",
       " '1/2 tsp baking soda',\n",
       " '1/4 tsp salt',\n",
       " '1 cup buttermilk',\n",
       " '1 large egg',\n",
       " '2 tbsp melted butter',\n",
       " '1 cup fresh blueberries',\n",
       " 'Butter or oil for cooking']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"ingredients\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b70b33b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a large bowl, whisk together flour, sugar, baking powder, baking soda, and salt.',\n",
       " 'In a separate bowl, mix buttermilk, egg, and melted butter.',\n",
       " \"Pour the wet ingredients into the dry ingredients and stir until just combined. Be careful not to overmix; it's okay if the batter is a bit lumpy.\",\n",
       " 'Gently fold in the fresh blueberries.',\n",
       " 'Heat a non-stick skillet or griddle over medium heat and add a small amount of butter or oil.',\n",
       " 'Pour about 1/4 cup of batter onto the skillet for each pancake.',\n",
       " 'Cook until bubbles form on the surface of the pancake, then flip and cook for another 1-2 minutes until golden brown.',\n",
       " 'Repeat with the remaining batter, adding more butter or oil to the skillet as needed.',\n",
       " 'Serve the blueberry pancakes warm with maple syrup, additional blueberries, and a pat of butter.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"instructions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2ef3f",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba7e9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You're a professional English-Italian translator.\"}, \n",
    "              {\"role\": \"user\", \"content\": \"Translate 'Be the change that you wish to see in the world.' into Italian\"}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58092e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Sii il cambiamento che desideri vedere nel mondo.\"'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031c6bf",
   "metadata": {},
   "source": [
    "# Process unstructured information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52717854",
   "metadata": {},
   "source": [
    "Inspired by https://platform.openai.com/examples/default-parse-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e87924da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"There are many fruits that were found on the recently discovered planet Goocrux. \n",
    "There are neoskizzles that grow there, which are purple and taste like candy. There are also \n",
    "loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits \n",
    "are a bright green color and are more savory than sweet. There are also plenty of loopnovas which \n",
    "are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which \n",
    "have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "600e6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You will be provided with unstructured data, and your task is to parse it into CSV format.\"}, \n",
    "        {\"role\": \"user\", \n",
    "         \"content\": prompt}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70f57a63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit,Color,Flavor\n",
      "neoskizzles,Purple,Candy\n",
      "loheckles,Grayish blue,Tart\n",
      "pounits,Bright green,Savory\n",
      "loopnovas,Neon pink,Cotton candy\n",
      "glowls,Pale orange,Sour and bitter\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edc461df",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[{\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"\"\"\n",
    "            Read this paragraph \n",
    "            \n",
    "            `%s` \n",
    "            \n",
    "            and use it to answer some questions.\"\"\" % prompt\n",
    "                }, \n",
    "                {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What are pounits?\"\n",
    "    }],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e54d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pounits are bright green fruits found on the planet Goocrux. They are described as more savory than sweet.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d7724",
   "metadata": {},
   "source": [
    "<center>\n",
    "     <img src=\"https://raw.githubusercontent.com/DataForScience/Networks/master/data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
